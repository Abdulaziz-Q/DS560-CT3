{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Critical Thinking 3 \n",
    "\n",
    "## Data Classification\n",
    "\n",
    "<br>\n",
    "Course Code: DS560 <br>\n",
    "Course Name: Advanced Data Mining <br>\n",
    "CRN: 24539 <br>\n",
    "Dr. Mohammad Abdelrahman\n",
    "\n",
    "Student ID: G200007615 <br>\n",
    "Student Name: Abdulaziz Alqumayzi<br>\n",
    "Date: 20/03/2021\n",
    "\n",
    "#### Requirements \n",
    "- Colab or Jupyter notebook to run the code.\n",
    "- Pandas and sklearn packages.\n",
    "- IRIS.csv file\n",
    "\n",
    "## Table of contents:\n",
    "- [Task-1](#task1)\n",
    "- [Task-2](#task2)\n",
    "- [Task-3](#task3)\n",
    "- [Task-4](#task4)\n",
    "- [References](#ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing needed packages\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import neighbors\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading iris dataset\n",
    "df = pd.read_csv('IRIS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='task1'></a>\n",
    "#### Task-1: \n",
    "An explanation about different classes that already exist in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Iris flower data set or Fisher's Iris data set is a multivariate data set introduced by the British statistician, eugenicist, and biologist Ronald Fisher in his 1936 paper The use of multiple measurements in taxonomic problems as an example of linear discriminant analysis.<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check all classes in species column\n",
    "df['species'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters.<br>\n",
    "\n",
    "**Iris setosa**, the **bristle-pointed iris**, is a species of flowering plant in the genus Iris of the family Iridaceae, it belongs the subgenus Limniris and the series Tripetalae. It is a rhizomatous perennial from a wide range across the Arctic sea, including Alaska, Maine, Canada, Russia, northeastern Asia, China, Korea and southwards to Japan.<br>\n",
    "\n",
    "**Iris virginica**, with the common name **Virginia iris**, is a perennial species of flowering plant, native to eastern North America.<br>\n",
    "\n",
    "**Iris versicolor** is also commonly known as the **blue flag**, **harlequin blueflag**, **larger blue flag**, **northern blue flag**, and **poison flag**, plus other variations of these names,and in Britain and Ireland as **purple iris**. It is a species of Iris native to North America, in the Eastern United States and Eastern Canada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='task2'></a>\n",
    "#### Task-2: \n",
    "Python code that builds different data classifiers (at least two) using the different classification algorithms, trains those classifiers using the training data, and displays their accuracy results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['sepal_length','sepal_width','petal_length','petal_width']],\n",
    "                                                    df['species'], test_size=0.20) # 80% training and 20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "# Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-setosa', 'Iris-virginica', 'Iris-versicolor',\n",
       "       'Iris-virginica', 'Iris-versicolor', 'Iris-virginica',\n",
       "       'Iris-versicolor', 'Iris-setosa', 'Iris-versicolor', 'Iris-setosa',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-virginica', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-virginica', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-setosa'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction results of SVM\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy of the support vector machines SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(df[['sepal_length','sepal_width','petal_length','petal_width']],\n",
    "                                                    df['species'], test_size=0.20) # 80% training and 20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a k-nearest neighbors Classifier\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Train the model using the training sets\n",
    "knn.fit(X_train_2, y_train_2)\n",
    "\n",
    "# Predict the response for test dataset\n",
    "y_pred_2 = knn.predict(X_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-versicolor', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-versicolor', 'Iris-virginica', 'Iris-setosa',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-virginica', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-versicolor', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-virginica', 'Iris-versicolor', 'Iris-setosa',\n",
       "       'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction results of k-nearest neighbors\n",
    "y_pred_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy of the k-nearest neighbors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_test_2, y_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(df[['sepal_length','sepal_width','petal_length','petal_width']],\n",
    "                                                    df['species'], test_size=0.20) # 80% training and 20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a Gaussian Naive Bayes Classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Train the model using the training sets and predict the response for test dataset\n",
    "y_pred_3 = gnb.fit(X_train_3, y_train_3).predict(X_test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-versicolor', 'Iris-setosa', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-setosa', 'Iris-virginica',\n",
       "       'Iris-versicolor', 'Iris-virginica', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-setosa', 'Iris-setosa', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-versicolor', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-setosa', 'Iris-setosa', 'Iris-virginica',\n",
       "       'Iris-setosa', 'Iris-virginica', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-virginica', 'Iris-setosa', 'Iris-versicolor',\n",
       "       'Iris-virginica', 'Iris-versicolor', 'Iris-setosa'], dtype='<U15')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy of the Gaussian Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_3, y_pred_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='task3'></a>\n",
    "#### Task-3: \n",
    "Python code to run those classifiers on the test data and compare their results and accuracy. Discuss the reasons for different accuracies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codes to run the classifiers are in the previous **task 3**.<br>\n",
    "\n",
    "A Classification report is used to measure the quality of predictions from a classification algorithm. How many predictions are True and how many are False. More specifically, True Positives, False Positives, True negatives and False Negatives are used to predict the metrics of a classification report as shown above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: results will change every run of the models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM report: \n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         7\n",
      "Iris-versicolor       1.00      0.93      0.97        15\n",
      " Iris-virginica       0.89      1.00      0.94         8\n",
      "\n",
      "       accuracy                           0.97        30\n",
      "      macro avg       0.96      0.98      0.97        30\n",
      "   weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('SVM report:','\\n')\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-nearest neighbors report: \n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        12\n",
      "Iris-versicolor       1.00      1.00      1.00         6\n",
      " Iris-virginica       1.00      1.00      1.00        12\n",
      "\n",
      "       accuracy                           1.00        30\n",
      "      macro avg       1.00      1.00      1.00        30\n",
      "   weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('k-nearest neighbors report:','\\n')\n",
    "print(classification_report(y_test_2, y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes report: \n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        11\n",
      "Iris-versicolor       0.89      0.89      0.89         9\n",
      " Iris-virginica       0.90      0.90      0.90        10\n",
      "\n",
      "       accuracy                           0.93        30\n",
      "      macro avg       0.93      0.93      0.93        30\n",
      "   weighted avg       0.93      0.93      0.93        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Gaussian Naive Bayes report:','\\n')\n",
    "print(classification_report(y_test_3, y_pred_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='task4'></a>\n",
    "#### Task-4: \n",
    "A summary of the results and findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision**: is the total number of correct predictions for a given digit divided by the total number of predictions for that digit.<br> \n",
    "- **Precision**: Accuracy of positive predictions.<br>\n",
    "- **Precision** = TP/(TP + FP)\n",
    "\n",
    "**Recall**: is the total number of correct predictions for a given digit divided by the total number of samples that should have been predicted as that digit.<br> \n",
    "- **Recall**: Fraction of positives that were correctly identified.<br>\n",
    "- **Recall** = TP/(TP+FN)\n",
    "\n",
    "**F1-score**: This is the average of the precision and the recall. <br>\n",
    "- **F1 Score** = 2*(Recall * Precision) / (Recall + Precision)\n",
    "\n",
    "**Support**: The number of samples with a given expected value.\n",
    "\n",
    "**Accuracy** is one metric for evaluating classification models. Informally, accuracy is the fraction of predictions our model got right. Formally, accuracy has the following definition:<br>\n",
    "- **Accuracy**: number of correct predictions divided by total number of predictions  \n",
    "- **Accuracy** = TP+TN/TP+TN+FP+FN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All classifiers did well because its Iris dataset had high-quality data. In real-life cases, the results will differ from these results.<br> \n",
    "\n",
    "In the **accuracy** metric, we can see both SVM and KNN did better than Gaussian Naive Bayes(GNB), but it didn't mean that GNB did badly; the GNB model did excellent predictions.<br>  \n",
    "\n",
    "In **precision** metric, only one class which is Iris-setosa was predicted correctly in all models and got 1 which means all predictions were correct. other classes got at least 0.82 out of 1 which is a very good prediction to other classes.<br> \n",
    "\n",
    "In **recall** metric, the same previous metric result. Only one class was predicted correctly which is Iris-setosa in all models. other classes got at least 0.80 which is a good prediction.<br>  \n",
    "\n",
    "In **f1-score** metric, also one class was predicted correctly which is Iris-setosa in all models. other classes got at least 0.89 which is a good prediction.<br>  \n",
    "\n",
    "**Support** is the number of actual occurrences of the class in the specified dataset. Imbalanced support in the training data may indicate structural weaknesses in the reported scores of the classifiers and could indicate the need for stratified sampling or rebalancing.<br>\n",
    "\n",
    "Best performance in **support** metric is Gaussian Naive Bayes model, other models were not balanced well. <br>\n",
    "\n",
    "Overall, the models did very good because the quality of Iris dataset, in real world cases we may not face as good as these results until we manage of the quality of the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ref'></a>\n",
    "#### References\n",
    "- Madhavan, S. (2015). Mastering Python for data science explore the world of data science through Python and learn how to make sense of data. Birmingham: Packt Publ.\n",
    "- Iris flower data set. (2021, February 25). Retrieved March 20, 2021, from https://en.wikipedia.org/wiki/Iris_flower_data_set\n",
    "- Iris setosa. (2020, December 13). Retrieved March 20, 2021, from https://en.wikipedia.org/wiki/Iris_setosa\n",
    "- Iris virginica. (2020, August 04). Retrieved March 20, 2021, from https://en.wikipedia.org/wiki/Iris_virginica\n",
    "- Iris versicolor. (2021, March 03). Retrieved March 20, 2021, from https://en.wikipedia.org/wiki/Iris_versicolor\n",
    "- Navlani, A. (2019). (Tutorial) support vector Machines (svm) in scikit-learn. Retrieved March 20, 2021, from https://www.datacamp.com/community/tutorials/svm-classification-scikit-learn-python#building\n",
    "- 1. supervised learningÂ¶. Retrieved March 20, 2021, from https://scikit-learn.org/stable/supervised_learning.html#supervised-learning\n",
    "- Muthu. (2018). Understanding the classification report through sklearn. Retrieved March 20, 2021, from https://muthu.co/understanding-the-classification-report-in-sklearn/#:~:text=A%20Classification%20report%20is%20used,classification%20report%20as%20shown%20below.\n",
    "- Kohli, S. (2019, November 18). Understanding a classification report for your machine learning model. Retrieved March 20, 2021, from https://medium.com/@kohlishivam5522/understanding-a-classification-report-for-your-machine-learning-model-88815e2ce397\n",
    "- Deitel, P. (2021). INTRO TO PYTHON FOR COMPUTER SCIENCE AND DATA SCIENCE: Learning to program with ai, big data... and the cloud, global edition. S.l.: PEARSON EDUCATION LIMITED.\n",
    "- Classification: Accuracy | machine learning crash course. Retrieved March 20, 2021, from https://developers.google.com/machine-learning/crash-course/classification/accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
